# -*- coding: utf-8 -*-
# ğŸ“¦ Shopee Mass Upload Excelä½œæˆã‚¢ãƒ—ãƒªï¼ˆãƒ•ãƒ«ç‰ˆãƒ»è¡Œæ‹¡å¼µ ä¿®æ­£æ¸ˆã¿ï¼‰
# - media_info: Option 1ã€œ30 Name/Image ã‚’ç¸¦æŒã¡åŒ–ï¼ˆå®Ÿåˆ—åã«å¯¾å¿œï¼‰
# - product_id Ã— variation_nameï¼ˆæ­£è¦åŒ–ï¼‰ã§çªåˆ
# - å…¬å¼ãƒ†ãƒ³ãƒ—ãƒ¬ã®ã€ŒImage per Variationã€åˆ—ã¸URLã‚’æ›¸ãè¾¼ã¿
# - å•†å“èª¬æ˜ã‚’çµåˆ
# - æœªãƒãƒƒãƒä¸€è¦§CSV / mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSVã‚’å‡ºåŠ›
# - ãƒ˜ãƒƒãƒ€ãƒ¼ç ´æé˜²æ­¢ã®ãŸã‚ã€Excelã¯ã€Œ2è¡Œç›®ã‹ã‚‰ã€æ›¸ãè¾¼ã¿

import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
from io import BytesIO
from openpyxl import load_workbook

st.set_page_config(page_title="Shopee Mass Upload Builder", layout="wide")
st.title("ğŸ“¦ Shopee Mass Upload Excelä½œæˆã‚¢ãƒ—ãƒªï¼ˆãƒ•ãƒ«ç‰ˆï¼‰")

# ğŸŸ¡ æ³¨æ„ã‚³ãƒ¡ãƒ³ãƒˆ + è£œåŠ©ç”»åƒ
st.markdown("### âš ï¸ STEP1~4ã®Excelã¯ã€**ä¿è­·è§£é™¤â†’ä¿å­˜ã—ç›´ã—**ã®ã†ãˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
st.image("images/unlock_tip.png", width=640)

# === ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ ===
basic_info_path    = st.file_uploader("STEP1: basic_info", type=["xlsx"], key="basic")
sales_info_path    = st.file_uploader("STEP2: sales_info", type=["xlsx"], key="sales")
media_info_path    = st.file_uploader("STEP3: media_info", type=["xlsx"], key="media")
shipment_info_path = st.file_uploader("STEP4: shipment_info", type=["xlsx"], key="shipment")
template_path      = st.file_uploader("STEP5: Shopeeå…¬å¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", type=["xlsx"], key="template")

# === ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ===
INSTRUCTION_ROWS = 5  # mass_update_* ã®ä¸Šéƒ¨èª¬æ˜è¡Œæ•°

def normalize_columns(cols):
    """Shopeeãƒ†ãƒ³ãƒ—ãƒ¬ç‰¹æœ‰ã® |n|n ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»"""
    return [re.sub(r"\|\d+\|\d+$", "", str(c)).strip() for c in cols]

def clean_name(x):
    """ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åã®æ­£è¦åŒ–"""
    if pd.isna(x):
        return None
    s = unicodedata.normalize("NFKC", str(x))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s).replace("\r", " ").replace("\n", " ").replace("\t", " ")
    return s.strip() or None

def to_str_id(x):
    """Excelæ•°å€¤â†’æ–‡å­—åˆ—åŒ–ï¼ˆ12345.0 â†’ 12345ï¼‰"""
    if pd.isna(x):
        return None
    s = str(x).strip()
    if re.fullmatch(r"\d+\.0", s):
        s = s[:-2]
    return s

def find_image_per_variation_col(norm_cols):
    """ãƒ†ãƒ³ãƒ—ãƒ¬å†…ã®ã€Image per Variationã€åˆ—ï¼ˆæ­£è¦åŒ–åï¼‰ã‚’è‡ªå‹•æ¤œå‡º"""
    for p in [r"(?i)image\s*per\s*variation", r"(?i)et_title_image_per_variation"]:
        for c in norm_cols:
            if re.search(p, c):
                return c
    return None

def detect_pairs_media_columns(media_df):
    """
    media_info ã®å®Ÿåˆ—åã«åˆã‚ã›ãŸ Name/Image ã®30ãƒšã‚¢ã‚’æŠ½å‡º
    - Name : et_title_option_{1..30}_for_variation_1
    - Image: et_title_option_image_{1..30}_for_variation_1
    """
    pairs = []
    for i in range(1, 30 + 1):
        name_col = f"et_title_option_{i}_for_variation_1"
        img_col  = f"et_title_option_image_{i}_for_variation_1"
        if name_col in media_df.columns and img_col in media_df.columns:
            pairs.append((i, name_col, img_col))
    return pairs

def df_to_csv_bytes(df: pd.DataFrame) -> BytesIO:
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    buf.seek(0)
    return buf

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if all([basic_info_path, sales_info_path, media_info_path, shipment_info_path, template_path]):

    # ===== å–ã‚Šè¾¼ã¿ =====
    try:
        basic_df    = pd.read_excel(basic_info_path,    sheet_name="Sheet1")
        sales_df    = pd.read_excel(sales_info_path,    sheet_name="Sheet1")
        media_df    = pd.read_excel(media_info_path,    sheet_name="Sheet1")
        shipment_df = pd.read_excel(shipment_info_path, sheet_name="Sheet1")
        template_df = pd.read_excel(template_path,      sheet_name="Template")
    except Exception as e:
        st.error(f"Excelèª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    # å…¬å¼åˆ—åï¼ˆé †åºä¿æŒï¼‰
    original_columns     = template_df.columns
    original_cols_normal = normalize_columns(original_columns)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ã‚’å‡¦ç†ç”¨ã«æ­£è¦åŒ–
    template_df_norm = template_df.copy()
    template_df_norm.columns = original_cols_normal

    # === â˜…æ ¸å¿ƒãƒ–ãƒ­ãƒƒã‚¯ï¼šè¡Œæ‹¡å¼µï¼ˆã“ã“ãŒã‚­ãƒ¢ï¼‰ ===
    start = INSTRUCTION_ROWS                 # ãƒ‡ãƒ¼ã‚¿é–‹å§‹ä½ç½®ï¼ˆèª¬æ˜è¡Œã®ç›´å¾Œï¼‰
    n = max(0, len(sales_df) - start)        # ãƒ‡ãƒ¼ã‚¿è¡Œæ•°
    rows_needed = start + n
    if len(template_df_norm) < rows_needed:
        template_df_norm = pd.concat(
            [template_df_norm, pd.DataFrame([{}] * (rows_needed - len(template_df_norm)))],
            ignore_index=True
        )

    # æ¬ ã‘ã¦ã„ã‚‹å…¬å¼åˆ—ãŒã‚ã‚Œã°ç©ºã§è£œå®Œ
    for col in original_cols_normal:
        if col not in template_df_norm.columns:
            template_df_norm[col] = None
    template_df_norm = template_df_norm[original_cols_normal]

    sl = slice(start, start + n)  # ä»¥é™ã€Œé–‹å§‹è¡Œä»¥é™ã®ã¿ã€ä¸Šæ›¸ã

    # ===== sales / shipment ã®å€¤ã‚’åŸ‹ã‚è¾¼ã¿ =====
    template_df_norm.loc[sl, "et_title_variation_integration_no"] = sales_df["et_title_product_id"].iloc[start:].values
    template_df_norm.loc[sl, "et_title_variation_id"]             = sales_df["et_title_variation_id"].iloc[start:].values
    template_df_norm.loc[sl, "ps_product_name"]                   = sales_df["et_title_product_name"].iloc[start:].values
    template_df_norm.loc[sl, "ps_sku_short"]                      = sales_df["et_title_variation_sku"].iloc[start:].values
    template_df_norm.loc[sl, "ps_price"]                          = sales_df["et_title_variation_price"].iloc[start:].values
    template_df_norm.loc[sl, "ps_stock"]                          = sales_df["et_title_variation_stock"].iloc[start:].values
    template_df_norm.loc[sl, "et_title_option_for_variation_1"]   = sales_df["et_title_variation_name"].iloc[start:].values
    if "et_title_variation_1" in template_df_norm.columns:
        template_df_norm.loc[sl, "et_title_variation_1"]          = "type"
    if "ps_weight" in template_df_norm.columns:
        template_df_norm.loc[sl, "ps_weight"]                     = shipment_df["et_title_product_weight"].iloc[start:].values
    if "channel_id.28057" in template_df_norm.columns:
        template_df_norm.loc[sl, "channel_id.28057"]              = "On"

    # ä¾¡æ ¼æ›ç®—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    with st.expander("ğŸ’± ä¾¡æ ¼æ›ç®—ï¼ˆSGDâ†’MYRï¼‰"):
        do_fx   = st.checkbox("SGDâ†’MYRã‚’æ›ã‘ã‚‹", value=True)
        fx_rate = st.number_input("ãƒ¬ãƒ¼ãƒˆ", value=3.4, step=0.1, format="%.2f")
    if do_fx and "ps_price" in template_df_norm.columns:
        template_df_norm.loc[sl, "ps_price"] = pd.to_numeric(
            template_df_norm.loc[sl, "ps_price"], errors="coerce"
        ).mul(fx_rate).round(2)

    # ===== media_info: Option 1ã€œ30 Name/Image ã‚’ç¸¦æŒã¡åŒ– =====
    pairs = detect_pairs_media_columns(media_df)
    media_long_list = []
    for _, name_col, img_col in pairs:
        tmp = media_df[["et_title_product_id", name_col, img_col]].copy()
        tmp.rename(columns={name_col: "variation_name_raw", img_col: "variation_image"}, inplace=True)
        tmp["product_id"]      = tmp["et_title_product_id"].map(to_str_id)
        tmp["variation_name"]  = tmp["variation_name_raw"].map(clean_name)
        tmp["variation_image"] = tmp["variation_image"].astype(str).str.strip()
        tmp = tmp[(tmp["product_id"].notna()) & (tmp["variation_name"].notna()) & (tmp["variation_image"] != "")]
        media_long_list.append(tmp[["product_id", "variation_name", "variation_image"]])
    media_long = pd.concat(media_long_list, ignore_index=True) if media_long_list else pd.DataFrame(columns=["product_id","variation_name","variation_image"])
    # æ•°å€¤ä»¥å¤–ã® product_idï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼æ··å…¥ãªã©ï¼‰ã‚’æ’é™¤
    media_long = media_long[media_long["product_id"].str.fullmatch(r"\d+")]
    media_long = (media_long
                  .sort_values(["product_id", "variation_name"])
                  .drop_duplicates(["product_id", "variation_name"], keep="first"))

    # ===== saleså´ã‚­ãƒ¼ã‚’æ­£è¦åŒ–ï¼ˆçªåˆç”¨ï¼‰ =====
    variation_map = sales_df[["et_title_product_id", "et_title_variation_name"]].copy()
    variation_map["product_id"]     = variation_map["et_title_product_id"].map(to_str_id)
    variation_map["variation_name"] = variation_map["et_title_variation_name"].map(clean_name)
    variation_map = variation_map[["product_id", "variation_name"]].dropna().drop_duplicates()

    # ç”»åƒURLã‚’åˆæµ
    img_map = variation_map.merge(media_long, on=["product_id", "variation_name"], how="left")

    # ===== Templateå´ã«ç”»åƒã‚’å…¥ã‚Œã‚‹ =====
    template_df_norm["product_id"]     = template_df_norm["et_title_variation_integration_no"].map(to_str_id)
    template_df_norm["variation_name"] = template_df_norm["et_title_option_for_variation_1"].map(clean_name)

    image_per_var_col = find_image_per_variation_col(original_cols_normal)
    if not image_per_var_col:
        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Image per Variationã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    template_df_norm = template_df_norm.merge(
        img_map[["product_id", "variation_name", "variation_image"]],
        on=["product_id", "variation_name"],
        how="left"
    )
    template_df_norm.loc[sl, image_per_var_col] = template_df_norm.loc[sl, "variation_image"].values

    # ===== å•†å“èª¬æ˜ã‚’çµåˆ =====
    desc_df = basic_df[["et_title_product_id", "et_title_product_description"]].copy()
    desc_df.rename(columns={"et_title_product_id": "product_id"}, inplace=True)
    desc_df["product_id"] = desc_df["product_id"].map(to_str_id)
    template_df_norm = template_df_norm.merge(desc_df, on="product_id", how="left")
    if "ps_product_description" in template_df_norm.columns:
        template_df_norm.loc[sl, "ps_product_description"] = template_df_norm.loc[sl, "et_title_product_description"].values

    # ä¸€æ™‚åˆ—ã®å¾Œå§‹æœ« & åˆ—é †å¾©å…ƒ
    template_df_norm.drop(columns=["variation_image", "et_title_product_description", "product_id", "variation_name"],
                          inplace=True, errors="ignore")
    template_df_norm = template_df_norm[original_cols_normal]
    template_df_norm.columns = original_columns

    # ===== æœªãƒãƒƒãƒCSV / mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSV =====
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼ˆrawåã‚‚æŒã¤ï¼‰
    variation_map_dbg = sales_df[["et_title_product_id", "et_title_product_name", "et_title_variation_name"]].copy()
    variation_map_dbg["product_id"] = variation_map_dbg["et_title_product_id"].map(to_str_id)
    variation_map_dbg["variation_name_clean"] = variation_map_dbg["et_title_variation_name"].map(clean_name)
    variation_map_dbg = (variation_map_dbg[["product_id", "et_title_product_name", "et_title_variation_name", "variation_name_clean"]]
                         .dropna(subset=["product_id", "variation_name_clean"])
                         .drop_duplicates()
                         .rename(columns={"et_title_product_name": "product_name",
                                          "et_title_variation_name": "variation_name_sales_raw"}))

    img_map_dbg = variation_map.merge(media_long, on=["product_id", "variation_name"], how="left")
    img_map_dbg["has_url"] = img_map_dbg["variation_image"].notna() & (img_map_dbg["variation_image"] != "")

    media_candidates = (media_long.groupby("product_id")["variation_name"]
                        .agg(lambda s: " | ".join(sorted(set([x for x in s if isinstance(x, str)]))))
                        .reset_index()
                        .rename(columns={"variation_name": "media_candidates"}))

    unmatched = img_map_dbg[~img_map_dbg["has_url"]][["product_id", "variation_name"]].copy()
    unmatched = unmatched.rename(columns={"variation_name": "variation_name_clean"})
    unmatched = unmatched.merge(variation_map_dbg, on=["product_id", "variation_name_clean"], how="left")
    unmatched = unmatched.merge(media_candidates, on="product_id", how="left")
    unmatched = unmatched[["product_id", "product_name", "variation_name_sales_raw", "variation_name_clean", "media_candidates"]]

    # ===== Excelã¸å®‰å…¨ã«æ›¸ãæˆ»ã—ï¼ˆ2è¡Œç›®ã‹ã‚‰æ›¸ãï¼‰ =====
    wb = load_workbook(template_path, data_only=True)
    sh = wb["Template"]

    for r_idx, row in enumerate(template_df_norm.itertuples(index=False, name=None), start=2):
        for c_idx, val in enumerate(row, start=1):
            if isinstance(val, float) and np.isnan(val):
                val = None
            sh.cell(row=r_idx, column=c_idx, value=val)

    out_xlsx = BytesIO()
    wb.save(out_xlsx)
    out_xlsx.seek(0)

    # CSVãƒãƒƒãƒ•ã‚¡
    unmatched_csv = df_to_csv_bytes(unmatched)
    catalog_csv   = df_to_csv_bytes(media_long[["product_id", "variation_name", "variation_image"]])

    # ===== ç”»é¢å‡ºåŠ› =====
    matched_cnt = int(img_map_dbg["has_url"].sum())
    total_keys  = len(img_map_dbg)
    st.success(f"âœ… å®Œäº†ï¼šç”»åƒURLãƒãƒƒãƒ {matched_cnt}/{total_keys}ï¼ˆ{matched_cnt/total_keys:.2%}ï¼‰")
    st.download_button("ğŸ“¥ Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=out_xlsx,
                       file_name="shopee_mass_upload_output.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    st.download_button("â¬‡ï¸ æœªãƒãƒƒãƒä¸€è¦§CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=unmatched_csv,
                       file_name="unmatched_variations.csv", mime="text/csv")
    st.download_button("â¬‡ï¸ mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=catalog_csv,
                       file_name="media_variation_catalog.csv", mime="text/csv")

else:
    st.info("ä¸Šã®5ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦é¸æŠã™ã‚‹ã¨å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")