# -*- coding: utf-8 -*-
# ğŸ“¦ Shopee Mass Upload Excelä½œæˆã‚¢ãƒ—ãƒªï¼ˆãƒ•ãƒ«ç‰ˆï¼‰
# - media_info: Option 1ã€œ30 Name/Image ã‚’ç¸¦æŒã¡åŒ–
# - product_id Ã— variation_nameï¼ˆæ­£è¦åŒ–ï¼‰ã§çªåˆ
# - å…¬å¼ãƒ†ãƒ³ãƒ—ãƒ¬ã®ã€ŒImage per Variationã€åˆ—ã¸URLã‚’æ›¸ãè¾¼ã¿
# - å•†å“èª¬æ˜ç­‰ã‚’çµåˆ
# - æœªãƒãƒƒãƒä¸€è¦§CSV / mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSVã‚‚å‡ºåŠ›
# â€» ãƒ˜ãƒƒãƒ€ãƒ¼ç ´æé˜²æ­¢ã®ãŸã‚ã€Excelã¯ã€Œ2è¡Œç›®ã‹ã‚‰ã€æ›¸ãè¾¼ã¿

import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
from io import BytesIO
from openpyxl import load_workbook

st.set_page_config(page_title="Shopee Mass Upload Builder", layout="wide")
st.title("ğŸ“¦ Shopee Mass Upload Excelä½œæˆã‚¢ãƒ—ãƒªï¼ˆãƒ•ãƒ«ç‰ˆï¼‰")

# ğŸŸ¡ æ³¨æ„ã‚³ãƒ¡ãƒ³ãƒˆ + è£œåŠ©ç”»åƒ
st.markdown("### âš ï¸ STEP1~4ã«å¿…è¦ãªExcelã‚·ãƒ¼ãƒˆã¯ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã«ä¿è­·è§£é™¤â†’**ä¿å­˜ã—ç›´ã—ã¦ã‹ã‚‰**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
st.image("images/unlock_tip.png", width=600)

# === ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ ===
basic_info_path    = st.file_uploader("STEP1: basic_info", type=["xlsx"], key="basic")
sales_info_path    = st.file_uploader("STEP2: sales_info", type=["xlsx"], key="sales")
media_info_path    = st.file_uploader("STEP3: media_info", type=["xlsx"], key="media")
shipment_info_path = st.file_uploader("STEP4: shipment_info", type=["xlsx"], key="shipment")
template_path      = st.file_uploader("STEP5: Shopeeå…¬å¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", type=["xlsx"], key="template")

# === ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ===
INSTRUCTION_ROWS = 5  # mass_update_* ã®ä¸Šéƒ¨èª¬æ˜è¡Œã®æƒ³å®šè¡Œæ•°ï¼ˆå¿…è¦ãªã‚‰èª¿æ•´ï¼‰

def normalize_columns(cols):
    """Shopeeãƒ†ãƒ³ãƒ—ãƒ¬ç‰¹æœ‰ã® |n|n ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ã—ã¦å‡¦ç†ç”¨åã«ã™ã‚‹"""
    return [re.sub(r"\|\d+\|\d+$", "", str(c)).strip() for c in cols]

def clean_name(x):
    """ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³åã®æ­£è¦åŒ–ï¼ˆNFKC / å…¨è§’ç©ºç™½â†’åŠè§’ / é€£ç¶šç©ºç™½â†’å˜ä¸€ / æ”¹è¡Œã‚¿ãƒ–é™¤å» / stripï¼‰"""
    if pd.isna(x):
        return None
    s = unicodedata.normalize("NFKC", str(x))
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s).replace("\r", " ").replace("\n", " ").replace("\t", " ")
    return s.strip() or None

def to_str_id(x):
    """Excelã§æ•°å€¤æ‰±ã„ã•ã‚ŒãŸID(ä¾‹: '123456.0')ã‚’å®‰å…¨ã«æ–‡å­—åˆ—ã¸"""
    if pd.isna(x):
        return None
    s = str(x).strip()
    if re.fullmatch(r"\d+\.0", s):
        s = s[:-2]
    return s

def find_image_per_variation_col(norm_cols):
    """ãƒ†ãƒ³ãƒ—ãƒ¬å†…ã®ã€Image per Variationã€åˆ—ï¼ˆæ­£è¦åŒ–åï¼‰ã‚’è‡ªå‹•æ¤œå‡º"""
    pats = [r"(?i)image\s*per\s*variation", r"(?i)et_title_image_per_variation"]
    for p in pats:
        for c in norm_cols:
            if re.search(p, c):
                return c
    return None

def detect_pairs_media_columns(media_df):
    """
    media_info ã®å®Ÿåˆ—åã«åˆã‚ã›ãŸ Name/Image ã®30ãƒšã‚¢ã‚’æŠ½å‡º
    - Name: et_title_option_{1..30}_for_variation_1
    - Image: et_title_option_image_{1..30}_for_variation_1
    """
    pairs = []
    for i in range(1, 30 + 1):
        name_col = f"et_title_option_{i}_for_variation_1"
        img_col  = f"et_title_option_image_{i}_for_variation_1"
        if name_col in media_df.columns and img_col in media_df.columns:
            pairs.append((i, name_col, img_col))
    return pairs

def df_to_csv_bytes(df: pd.DataFrame) -> BytesIO:
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    buf.seek(0)
    return buf

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if all([basic_info_path, sales_info_path, media_info_path, shipment_info_path, template_path]):

    # ===== å–ã‚Šè¾¼ã¿ =====
    try:
        basic_df    = pd.read_excel(basic_info_path,    sheet_name="Sheet1")
        sales_df    = pd.read_excel(sales_info_path,    sheet_name="Sheet1")
        media_df    = pd.read_excel(media_info_path,    sheet_name="Sheet1")
        shipment_df = pd.read_excel(shipment_info_path, sheet_name="Sheet1")
        template_df = pd.read_excel(template_path,      sheet_name="Template")
    except Exception as e:
        st.error(f"Excelèª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    # å…¬å¼åˆ—åï¼ˆé †åºä¿æŒç”¨ï¼‰
    original_columns     = template_df.columns
    original_cols_normal = normalize_columns(original_columns)

    # ãƒ†ãƒ³ãƒ—ãƒ¬ã‚’å‡¦ç†ç”¨ã«æ­£è¦åŒ–
    template_df_norm = template_df.copy()
    template_df_norm.columns = original_cols_normal

    # æ¬ ã‘ã¦ã„ã‚‹å…¬å¼åˆ—ãŒã‚ã‚Œã°ç©ºã§è£œå®Œ
    for col in original_cols_normal:
        if col not in template_df_norm.columns:
            template_df_norm[col] = None
    template_df_norm = template_df_norm[original_cols_normal]

    # ===== sales / shipment ç­‰ã€é–‹å§‹è¡Œä»¥é™ã®å€¤ã‚’æº–å‚™ =====
    start = INSTRUCTION_ROWS  # DataFrameã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã®é–‹å§‹ï¼ˆä¸Šéƒ¨èª¬æ˜è¡Œã®ä¸‹ã‹ã‚‰ï¼‰
    n = max(0, len(sales_df) - start)
    sl = slice(start, start + n)

    # å¿…è¦åˆ—ãŒå­˜åœ¨ã™ã‚‹æ™‚ã®ã¿ä»£å…¥ï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ã§å£Šã‚Œã«ããï¼‰
    def safe_set(col, series):
        if col in template_df_norm.columns:
            template_df_norm.loc[sl, col] = series.iloc[start:].values

    safe_set("et_title_variation_integration_no", sales_df["et_title_product_id"])
    safe_set("et_title_variation_id",             sales_df["et_title_variation_id"])
    safe_set("ps_product_name",                   sales_df["et_title_product_name"])
    safe_set("ps_sku_short",                      sales_df["et_title_variation_sku"])
    safe_set("ps_price",                          sales_df["et_title_variation_price"])
    safe_set("ps_stock",                          sales_df["et_title_variation_stock"])
    safe_set("et_title_option_for_variation_1",   sales_df["et_title_variation_name"])
    if "et_title_variation_1" in template_df_norm.columns:
        template_df_norm.loc[sl, "et_title_variation_1"] = "type"
    safe_set("ps_weight",                         shipment_df["et_title_product_weight"])
    if "channel_id.28057" in template_df_norm.columns:
        template_df_norm.loc[sl, "channel_id.28057"] = "On"

    # ä¾¡æ ¼æ›ç®—ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ONã«ã™ã‚‹ï¼‰
    with st.expander("ğŸ’± ä¾¡æ ¼æ›ç®—ï¼ˆSGDâ†’MYRï¼‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³"):
        do_fx = st.checkbox("SGDâ†’MYRã‚’æ›ã‘ã‚‹ï¼ˆ3.4Ã—ï¼‰", value=True)
        fx_rate = st.number_input("ãƒ¬ãƒ¼ãƒˆ", value=3.4, step=0.1, format="%.2f")
    if do_fx and "ps_price" in template_df_norm.columns:
        template_df_norm.loc[sl, "ps_price"] = pd.to_numeric(
            template_df_norm.loc[sl, "ps_price"], errors="coerce"
        ).mul(fx_rate).round(2)

    # ===== media_info: Option 1ã€œ30 Name/Image ã‚’ç¸¦æŒã¡åŒ– =====
    pairs = detect_pairs_media_columns(media_df)
    media_long_list = []
    for _, name_col, img_col in pairs:
        tmp = media_df[["et_title_product_id", name_col, img_col]].copy()
        tmp.rename(columns={name_col: "variation_name_raw", img_col: "variation_image"}, inplace=True)
        tmp["product_id"]      = tmp["et_title_product_id"].map(to_str_id)
        tmp["variation_name"]  = tmp["variation_name_raw"].map(clean_name)
        tmp["variation_image"] = tmp["variation_image"].astype(str).str.strip()
        tmp = tmp[(tmp["product_id"].notna()) & (tmp["variation_name"].notna()) & (tmp["variation_image"] != "")]
        media_long_list.append(tmp[["product_id", "variation_name", "variation_image"]])

    if media_long_list:
        media_long = pd.concat(media_long_list, ignore_index=True)
        # æ•°å€¤ä»¥å¤–ã®product_idã‚’é™¤å¤–ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã®å–ã‚Šè¾¼ã¿äº‹æ•…ãªã©ã‚’å›é¿ï¼‰
        media_long = media_long[media_long["product_id"].str.fullmatch(r"\d+")]
        # åŒä¸€ã‚­ãƒ¼ã®é‡è¤‡ã¯æœ€åˆã®URLã‚’æ¡ç”¨
        media_long = (media_long
                      .sort_values(["product_id", "variation_name"])
                      .drop_duplicates(["product_id", "variation_name"], keep="first"))
    else:
        media_long = pd.DataFrame(columns=["product_id", "variation_name", "variation_image"])

    # ===== saleså´ã‚­ãƒ¼ã‚’æ­£è¦åŒ–ï¼ˆçªåˆç”¨ï¼‰ =====
    variation_map = sales_df[["et_title_product_id", "et_title_variation_name"]].copy()
    variation_map["product_id"]     = variation_map["et_title_product_id"].map(to_str_id)
    variation_map["variation_name"] = variation_map["et_title_variation_name"].map(clean_name)
    variation_map = variation_map[["product_id", "variation_name"]].dropna().drop_duplicates()

    # ç”»åƒURLã‚’åˆæµï¼ˆ98%ç¨‹åº¦ãŒä¸€è‡´ã™ã‚‹ã¯ãšï¼‰
    img_map = variation_map.merge(media_long, on=["product_id", "variation_name"], how="left")

    # ===== Templateå´ã®ã‚­ãƒ¼ã§ãƒãƒ¼ã‚¸ã—ã¦ã€Image per Variationã€åˆ—ã«æ›¸ã =====
    template_df_norm["product_id"]     = template_df_norm["et_title_variation_integration_no"].map(to_str_id)
    template_df_norm["variation_name"] = template_df_norm["et_title_option_for_variation_1"].map(clean_name)

    # å®Ÿåœ¨ã® Image per Variation åˆ—ã‚’æ¤œå‡º
    image_per_var_col = find_image_per_variation_col(original_cols_normal)
    if not image_per_var_col:
        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Image per Variationã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬åˆ—åã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.stop()

    # ãƒãƒ¼ã‚¸ã—ã¦ç”»åƒURLã‚’ä»˜ä¸
    template_df_norm = template_df_norm.merge(
        img_map[["product_id", "variation_name", "variation_image"]],
        on=["product_id", "variation_name"],
        how="left"
    )
    template_df_norm.loc[sl, image_per_var_col] = template_df_norm.loc[sl, "variation_image"].values

    # ===== å•†å“èª¬æ˜ã‚’çµåˆ =====
    desc_df = basic_df[["et_title_product_id", "et_title_product_description"]].copy()
    desc_df.rename(columns={"et_title_product_id": "product_id"}, inplace=True)
    desc_df["product_id"] = desc_df["product_id"].map(to_str_id)
    template_df_norm = template_df_norm.merge(desc_df, on="product_id", how="left")
    if "ps_product_description" in template_df_norm.columns:
        template_df_norm.loc[sl, "ps_product_description"] = template_df_norm.loc[sl, "et_title_product_description"].values

    # ä¸€æ™‚åˆ—ã®å¾Œå§‹æœ«
    template_df_norm.drop(columns=["variation_image", "et_title_product_description", "product_id", "variation_name"],
                          inplace=True, errors="ignore")

    # åˆ—é †ã‚’å…¬å¼ã«æ•´ãˆã€è¡¨ç¤ºåã‚’å…ƒã«æˆ»ã™
    template_df_norm = template_df_norm[original_cols_normal]
    template_df_norm.columns = original_columns

    # ===== æœªãƒãƒƒãƒCSV / mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSV ã‚’ä½œæˆ =====
    # ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ã« sales ã®å…ƒåãªã©ã‚‚ä¿æŒï¼‰
    variation_map_dbg = sales_df[["et_title_product_id", "et_title_product_name", "et_title_variation_name"]].copy()
    variation_map_dbg["product_id"] = variation_map_dbg["et_title_product_id"].map(to_str_id)
    variation_map_dbg["variation_name_clean"] = variation_map_dbg["et_title_variation_name"].map(clean_name)
    variation_map_dbg = (variation_map_dbg[["product_id", "et_title_product_name", "et_title_variation_name", "variation_name_clean"]]
                         .dropna(subset=["product_id", "variation_name_clean"])
                         .drop_duplicates()
                         .rename(columns={"et_title_product_name": "product_name",
                                          "et_title_variation_name": "variation_name_sales_raw"}))

    img_map_dbg = variation_map.merge(media_long, on=["product_id", "variation_name"], how="left")
    img_map_dbg["has_url"] = img_map_dbg["variation_image"].notna() & (img_map_dbg["variation_image"] != "")

    media_candidates = (media_long.groupby("product_id")["variation_name"]
                        .agg(lambda s: " | ".join(sorted(set([x for x in s if isinstance(x, str)]))))
                        .reset_index()
                        .rename(columns={"variation_name": "media_candidates"}))

    unmatched = img_map_dbg[~img_map_dbg["has_url"]][["product_id", "variation_name"]].copy()
    unmatched = unmatched.rename(columns={"variation_name": "variation_name_clean"})
    unmatched = unmatched.merge(variation_map_dbg, on=["product_id", "variation_name_clean"], how="left")
    unmatched = unmatched.merge(media_candidates, on="product_id", how="left")
    unmatched = unmatched[["product_id", "product_name", "variation_name_sales_raw", "variation_name_clean", "media_candidates"]]

    # ===== Excelã¸å®‰å…¨ã«æ›¸ãæˆ»ã—ï¼ˆ2è¡Œç›®ã‹ã‚‰æ›¸ãï¼šãƒ˜ãƒƒãƒ€ãƒ¼ä¿è­·ï¼‰ =====
    wb = load_workbook(template_path, data_only=True)
    sh = wb["Template"]

    # pandasã®è¡Œ0ãŒExcelã®ã€Œ2è¡Œç›®ã€ã«ç›¸å½“
    # â†’ èª¬æ˜è¡Œã‚‚å«ã‚ã€DataFrameã®å†…å®¹ã‚’ãã®ã¾ã¾2è¡Œç›®ä»¥é™ã«æ›¸ãæˆ»ã™
    for r_idx, row in enumerate(template_df_norm.itertuples(index=False, name=None), start=2):
        for c_idx, val in enumerate(row, start=1):
            if isinstance(val, float) and np.isnan(val):
                val = None
            sh.cell(row=r_idx, column=c_idx, value=val)

    # å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡
    out_xlsx = BytesIO()
    wb.save(out_xlsx)
    out_xlsx.seek(0)

    # CSVãƒãƒƒãƒ•ã‚¡
    unmatched_csv = df_to_csv_bytes(unmatched)
    catalog_csv   = df_to_csv_bytes(media_long[["product_id", "variation_name", "variation_image"]])

    # ===== ç”»é¢å‡ºåŠ› =====
    matched_cnt = int(img_map_dbg["has_url"].sum())
    total_keys  = len(img_map_dbg)
    st.success(f"âœ… å®Œäº†ï¼šç”»åƒURLãƒãƒƒãƒ {matched_cnt}/{total_keys}ï¼ˆ{matched_cnt/total_keys:.2%}ï¼‰")
    st.download_button(
        "ğŸ“¥ Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=out_xlsx,
        file_name="shopee_mass_upload_output.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    st.download_button("â¬‡ï¸ æœªãƒãƒƒãƒä¸€è¦§CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=unmatched_csv,
                       file_name="unmatched_variations.csv", mime="text/csv")
    st.download_button("â¬‡ï¸ mediaå€™è£œã‚«ã‚¿ãƒ­ã‚°CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=catalog_csv,
                       file_name="media_variation_catalog.csv", mime="text/csv")

else:
    st.info("ä¸Šã®5ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦é¸æŠã™ã‚‹ã¨å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
