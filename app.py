import streamlit as st
import pandas as pd
from io import BytesIO
from openpyxl import load_workbook
import re
import unicodedata
import numpy as np

st.title("ğŸ“¦ Shopee Mass Upload Excelä½œæˆã‚¢ãƒ—ãƒª")

# ğŸŸ¡ æ³¨æ„ã‚³ãƒ¡ãƒ³ãƒˆ + è£œåŠ©ç”»åƒ
st.markdown("### âš ï¸ STEP1~4ã«å¿…è¦ãªExcelã‚·ãƒ¼ãƒˆã¯ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã«ä¿è­·è§£é™¤â†’ä¿å­˜ã—ç›´ã—ã¦ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
st.image("images/unlock_tip.png", width=600)

# STEPã”ã¨ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
basic_info_path   = st.file_uploader("STEP1: basic_info", type=["xlsx"], key="basic")
sales_info_path   = st.file_uploader("STEP2: sales_info", type=["xlsx"], key="sales")
media_info_path   = st.file_uploader("STEP3: media_info", type=["xlsx"], key="media")
shipment_info_path= st.file_uploader("STEP4: shipment_info", type=["xlsx"], key="shipment")
template_path     = st.file_uploader("STEP5: Shopeeå…¬å¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", type=["xlsx"], key="template")

# â”€â”€ å…±é€š: åˆ—åæ­£è¦åŒ–ï¼ˆShopeeãƒ†ãƒ³ãƒ—ãƒ¬ç‰¹æœ‰ã® |n|n ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»ï¼‰ â”€â”€
def normalize_columns(cols):
    return [re.sub(r"\|\d+\|\d+$", "", str(c)).strip() for c in cols]

# â”€â”€ æ–‡å­—åˆ—æ­£è¦åŒ–ï¼ˆNFKCãƒ»å…¨åŠè§’ç©ºç™½ã‚’å˜ä¸€åŠè§’ã«ãƒ»ä¸¡ç«¯stripãƒ»æ”¹è¡Œã‚¿ãƒ–é™¤å»ï¼‰ â”€â”€
def clean_name(x):
    if pd.isna(x):
        return None
    s = str(x)
    s = unicodedata.normalize("NFKC", s)
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    s = s.replace("\r", " ").replace("\n", " ").replace("\t", " ")
    return s.strip() or None

# â”€â”€ product_id ã‚’æ–‡å­—åˆ—åŒ–ï¼ˆExcelã® 123456.0 å•é¡Œã‚’å¸åï¼‰ â”€â”€
def to_str_id(x):
    if pd.isna(x):
        return None
    s = str(x).strip()
    if re.fullmatch(r"\d+\.0", s):
        s = s[:-2]
    # å…ˆé ­ã‚¼ãƒ­ã‚’ä¿æŒã—ãŸã„å ´åˆãŒã‚ã‚‹ãŸã‚intåŒ–ã¯ã—ãªã„
    return s

# â”€â”€ media_info ã® Option Name/Image ã®åˆ—ãƒšã‚¢ã‚’ 1..30 ã§å³å¯†å¯¾å¿œ â”€â”€
def extract_option_pairs(columns):
    name_map = {}
    img_map  = {}
    for c in columns:
        cs = str(c)
        m1 = re.search(r"Option\s*Name\s*(\d+)$", cs, flags=re.I)
        m2 = re.search(r"Option\s*(\d+)\s*Name$", cs, flags=re.I)
        if m1 or m2:
            idx = int((m1 or m2).group(1))
            name_map[idx] = cs
        m3 = re.search(r"Option\s*Image\s*(\d+)$", cs, flags=re.I)
        m4 = re.search(r"Option\s*(\d+)\s*Image$", cs, flags=re.I)
        if m3 or m4:
            idx = int((m3 or m4).group(1))
            img_map[idx] = cs
    pairs = []
    for i in sorted(set(name_map.keys()) & set(img_map.keys())):
        pairs.append((i, name_map[i], img_map[i]))
    return pairs

if basic_info_path and sales_info_path and media_info_path and shipment_info_path and template_path:

    # ====== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ======
    basic_df    = pd.read_excel(basic_info_path,    sheet_name="Sheet1")
    sales_df    = pd.read_excel(sales_info_path,    sheet_name="Sheet1")
    media_df    = pd.read_excel(media_info_path,    sheet_name="Sheet1")
    shipment_df = pd.read_excel(shipment_info_path, sheet_name="Sheet1")
    template_df = pd.read_excel(template_path,      sheet_name="Template")

    # å…¬å¼åˆ—åï¼ˆé †åºä¿æŒç”¨ï¼‰
    original_columns = template_df.columns
    template_df_norm = template_df.copy()
    template_df_norm.columns = normalize_columns(template_df.columns)

    # ä¸è¶³åˆ—ã‚’è£œå®Œï¼ˆæ¬ ã‘ãŒã‚ã‚Œã°ç©ºåˆ—ã‚’è¿½åŠ ï¼‰
    for col in normalize_columns(original_columns):
        if col not in template_df_norm.columns:
            template_df_norm[col] = None
    template_df_norm = template_df_norm[normalize_columns(original_columns)]

    # ====== å–ã‚Šè¾¼ã¿å…ƒã®åŸºæœ¬åˆ—ï¼ˆé–‹å§‹è¡Œä»¥é™ã§åŸ‹ã‚ã‚‹ï¼‰ ======
    start_row = 5
    product_ids       = sales_df["et_title_product_id"].astype(object)
    variation_ids     = sales_df["et_title_variation_id"].astype(object)
    variation_names   = sales_df["et_title_variation_name"].astype(object)
    skus              = sales_df["et_title_variation_sku"].astype(object)
    variation_prices  = sales_df["et_title_variation_price"].astype(object)
    variation_stocks  = sales_df["et_title_variation_stock"].astype(object)
    product_names     = sales_df["et_title_product_name"].astype(object)
    weight_num        = shipment_df["et_title_product_weight"].astype(object)

    # SGDâ†’MYRæ›ç®—ï¼ˆå¿…è¦ãªã‚‰èª¿æ•´ï¼‰
    sgd_to_myr_rate = 3.4

    # è¡Œæ•°è¨ˆç®—ï¼ˆsales_dfã®ãƒ‡ãƒ¼ã‚¿éƒ¨ã«åˆã‚ã›ã‚‹ï¼‰
    n = len(product_ids) - start_row
    if n < 0:
        n = 0
    rows_needed = start_row + n
    if len(template_df_norm) < rows_needed:
        template_df_norm = pd.concat(
            [template_df_norm, pd.DataFrame([{}] * (rows_needed - len(template_df_norm)))],
            ignore_index=True
        )

    # ====== å€¤ã®åŸ‹ã‚è¾¼ã¿ï¼ˆé–‹å§‹è¡Œä»¥é™ï¼‰ ======
    sl = slice(start_row, start_row + n)

    template_df_norm.loc[sl, "et_title_variation_integration_no"] = product_ids.iloc[start_row:].values
    template_df_norm.loc[sl, "et_title_variation_id"]             = variation_ids.iloc[start_row:].values
    template_df_norm.loc[sl, "ps_product_name"]                   = product_names.iloc[start_row:].values
    template_df_norm.loc[sl, "ps_sku_short"]                      = skus.iloc[start_row:].values
    template_df_norm.loc[sl, "ps_price"]                          = variation_prices.iloc[start_row:].values
    template_df_norm.loc[sl, "ps_stock"]                          = variation_stocks.iloc[start_row:].values
    template_df_norm.loc[sl, "et_title_option_for_variation_1"]   = variation_names.iloc[start_row:].values
    template_df_norm.loc[sl, "et_title_variation_1"]              = "type"
    template_df_norm.loc[sl, "ps_weight"]                         = weight_num.iloc[start_row:].values
    template_df_norm.loc[sl, "channel_id.28057"]                  = "On"

    # ä¾¡æ ¼æ›ç®—
    template_df_norm.loc[sl, "ps_price"] = (
        pd.to_numeric(template_df_norm.loc[sl, "ps_price"], errors="coerce") * sgd_to_myr_rate
    ).round(2)

    # ====== media_info: Option 1ã€œ30 Name/Image ã‚’ç¸¦æŒã¡åŒ– ======
    pairs = extract_option_pairs(media_df.columns)
    media_long_list = []
    for idx, name_col, img_col in pairs:
        tmp = media_df[["et_title_product_id", name_col, img_col]].copy()
        tmp.rename(columns={name_col:"variation_name_raw", img_col:"variation_image"}, inplace=True)
        tmp["product_id"]    = tmp["et_title_product_id"].map(to_str_id)
        tmp["variation_name"]= tmp["variation_name_raw"].map(clean_name)
        tmp["variation_image"]= tmp["variation_image"].astype(str).str.strip()
        tmp = tmp[(tmp["variation_name"].notna()) & (tmp["variation_image"] != "") & (tmp["product_id"].notna())]
        media_long_list.append(tmp[["product_id","variation_name","variation_image"]])
    if media_long_list:
        media_long = pd.concat(media_long_list, ignore_index=True)
    else:
        media_long = pd.DataFrame(columns=["product_id","variation_name","variation_image"])

    # åŒä¸€ã‚­ãƒ¼ã§é‡è¤‡ãŒã‚ã‚Œã°æœ€åˆã®URLã‚’æ¡ç”¨
    if not media_long.empty:
        media_long = (media_long
                      .sort_values(["product_id","variation_name"])
                      .drop_duplicates(["product_id","variation_name"], keep="first"))

    # ====== saleså´ã® variation_map ã‚’æ­£è¦åŒ–ï¼ˆãƒãƒ¼ã‚¸ã‚­ãƒ¼çµ±ä¸€ï¼‰ ======
    variation_map = sales_df[["et_title_product_id","et_title_variation_name"]].copy()
    variation_map["product_id"]     = variation_map["et_title_product_id"].map(to_str_id)
    variation_map["variation_name"] = variation_map["et_title_variation_name"].map(clean_name)
    variation_map = variation_map[["product_id","variation_name"]].dropna().drop_duplicates()

    # ====== ç”»åƒURLã‚’ variation_map ã«åˆæµ ======
    img_map = pd.merge(variation_map, media_long, on=["product_id","variation_name"], how="left")
    # ç”»åƒãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚‚ã®ã¯ NaN ã®ã¾ã¾ï¼ˆå¾Œæ®µã§ãã®ã¾ã¾å…¥ã‚‹ï¼‰

    # ====== Templateã«ãƒãƒ¼ã‚¸ã—ã¦ et_title_image_per_variation ã‚’åŸ‹ã‚ã‚‹ ======
    template_df_norm["product_id"]    = template_df_norm["et_title_variation_integration_no"].map(to_str_id)
    template_df_norm["variation_name"]= template_df_norm["et_title_option_for_variation_1"].map(clean_name)

    template_df_norm = template_df_norm.merge(
        img_map[["product_id","variation_name","variation_image"]],
        on=["product_id","variation_name"],
        how="left"
    )

    # ã“ã“ãŒè‚: é–‹å§‹è¡Œä»¥é™ã®ã¿ç”»åƒã‚’æ›¸ãè¾¼ã‚€
    template_df_norm.loc[sl, "et_title_image_per_variation"] = template_df_norm.loc[sl, "variation_image"].values

    # ====== å•†å“èª¬æ˜ã‚’çµ±åˆ ======
    product_description_df = basic_df[["et_title_product_id","et_title_product_description"]].copy()
    product_description_df.rename(columns={"et_title_product_id":"product_id"}, inplace=True)
    product_description_df["product_id"] = product_description_df["product_id"].map(to_str_id)

    template_df_norm = template_df_norm.merge(product_description_df, on="product_id", how="left")
    template_df_norm.loc[sl, "ps_product_description"] = template_df_norm.loc[sl, "et_title_product_description"].values

    # ====== ä¸€æ™‚åˆ—ã®å¾Œå§‹æœ« ======
    template_df_norm.drop(columns=[
        "variation_image","et_title_product_description","product_id","variation_name"
    ], inplace=True, errors="ignore")

    # ====== åˆ—é †ã‚’å…¬å¼ã«æƒãˆã‚‹ï¼ˆä½™è¨ˆãªåˆ—ã¯ãªã„çŠ¶æ…‹ï¼‰ ======
    template_df_norm = template_df_norm[normalize_columns(original_columns)]
    # å…ƒã®ãƒ©ãƒ™ãƒ«ï¼ˆ|n|nä»˜ãã®è¡¨ç¤ºæ–‡å­—åˆ—ï¼‰ã«æˆ»ã™
    template_df_norm.columns = original_columns

    # ====== Excel æ›¸ãè¾¼ã¿ ======
    wb = load_workbook(template_path, data_only=True)
    sheet = wb["Template"]

    # å€¤ã ã‘ä¸Šæ›¸ãï¼ˆæ¤œè¨¼/ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ç­‰ã®å®šç¾©ã¯ç¶­æŒï¼‰
    for r_idx, row in enumerate(template_df_norm.itertuples(index=False, name=None), start=1):
        for c_idx, value in enumerate(row, start=1):
            sheet.cell(row=r_idx, column=c_idx, value=None if (isinstance(value, float) and np.isnan(value)) else value)

    buf = BytesIO()
    wb.save(buf)
    buf.seek(0)

    st.success("å‡¦ç†å®Œäº†ï¼šç”»åƒURLãƒ»èª¬æ˜æ–‡ãŒãƒãƒ¼ã‚¸ã•ã‚Œã¾ã—ãŸã€‚")
    st.download_button(
        label="ğŸ“¥ Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=buf,
        file_name="output_file.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
